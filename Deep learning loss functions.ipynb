{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e48fe7-dd77-4ea4-8c5b-dad222de971b",
   "metadata": {},
   "source": [
    "Below we compute function for calculating root mean squared error.. popularly used for regression.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a00956-e381-43c2-866b-15664c55ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d is: ['0.00000000', '0.16600000', '0.33300000']\n",
      "p is: ['0.00000000', '0.25400000', '0.99800000']\n",
      "rms error is: 0.3872849941150143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_hat = np.array([0.000, 0.166, 0.333])\n",
    "y_true = np.array([0.000, 0.254, 0.998])\n",
    "def rmse(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    differences_squared = differences ** 2\n",
    "    mean_of_differences_squared = differences_squared.mean()\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared)\n",
    "    return rmse_val\n",
    "print(\"d is: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"p is: \" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "rmse_val = rmse(y_hat, y_true)\n",
    "print(\"rms error is: \" + str(rmse_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256216f-a3de-4343-abae-b1dd8328de11",
   "metadata": {},
   "source": [
    "The mean absolute error is measured as the average of sum of absolute differences between predictions and actual observations. Like MSE, this as well measures the magnitude of error without considering their direction and it is very good when there are lots of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41286d17-addb-491b-8554-08d33239d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d is: ['0.00000000', '0.16600000', '0.33300000']\n",
      "p is: ['0.00000000', '0.25400000', '0.99800000']\n",
      "mae error is: 0.251\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_hat = np.array([0.000, 0.166, 0.333])\n",
    "y_true = np.array([0.000, 0.254, 0.998])\n",
    "\n",
    "print(\"d is: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"p is: \" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "\n",
    "def mae(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    absolute_differences = np.absolute(differences)\n",
    "    mean_absolute_differences = absolute_differences.mean()\n",
    "    return mean_absolute_differences\n",
    "mae_val = mae(y_hat, y_true)\n",
    "print (\"mae error is: \" + str(mae_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4ad03-8159-4e73-9802-c01ce772ab4b",
   "metadata": {},
   "source": [
    "mean bias error can be used to determine if our algorithm as a bias: negative or positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eccade-a582-4653-a96b-89bdd851c4bd",
   "metadata": {},
   "source": [
    "Hinge Loss/Multi class SVM Loss for SVM machines \n",
    "Consider an example where we have three training examples and three classes to predict â€” Dog, cat and horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67983d20-34c0-43c0-bcf6-1ddb369a6ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(0, (1.49) - (-0.39) + 1) + max(0, (4.21) - (-0.39) + 1)\n",
    "max(0, 2.88) + max(0, 5.6)\n",
    "2.88 + 5.6\n",
    "8.48 #(High loss as very wrong prediction)\n",
    "## 2nd training example\n",
    "max(0, (-4.61) - (3.28)+ 1) + max(0, (1.46) - (3.28)+ 1)\n",
    "max(0, -6.89) + max(0, -0.82)\n",
    "0 + 0\n",
    "0 #(Zero loss as correct prediction)\n",
    "## 3rd training example\n",
    "max(0, (1.03) - (-2.27)+ 1) + max(0, (-2.37) - (-2.27)+ 1)\n",
    "max(0, 4.3) + max(0, 0.9)\n",
    "4.3 + 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b33c73-4633-4d41-b35d-77302b9aa370",
   "metadata": {},
   "source": [
    "Cross Entropy Loss/Negative Log Likelihood\n",
    "\n",
    "this is the log function we have been using in andrew ng's logreg class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2925d4-92a2-4fde-9d18-5e7857fc601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy loss is: 0.7135329699138555\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = np.array([[0.25,0.25,0.25,0.25],\n",
    "                        [0.01,0.01,0.01,0.96]])\n",
    "targets = np.array([[0,0,0,1],\n",
    "                   [0,0,0,1]])\n",
    "def cross_entropy(predictions, targets, epsilon=1e-10):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce_loss = -np.sum(np.sum(targets * np.log(predictions + 1e-5)))/N\n",
    "    return ce_loss\n",
    "cross_entropy_loss = cross_entropy(predictions, targets)\n",
    "print (\"Cross entropy loss is: \" + str(cross_entropy_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a7f817-dac2-4ce8-9fac-fae1a87f363d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
